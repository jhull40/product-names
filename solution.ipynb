{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "\n",
    "a.) If we want to understand which catalog (such as clothing, shoes, accessories, beauty, jewelry etc.) each item is, how will you make that happen?\n",
    "\n",
    "\n",
    "b.) How can you extract the additional information from the item names, such as the color, style, size, material, gender etc. if there is any?\n",
    "\n",
    "\n",
    "c.) A plus. If you write the queries/codes, or build a machine learning model to achieve the goal of a.) or b.) above on the attached dataset. Python is preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A\n",
    "\n",
    "To understand the catalog that each item belongs to, I ran built topic models to cluster items. Then, using the output, I manually labeled the output data to map a topic to a physical catalog label.\n",
    "\n",
    "\n",
    "#### Processing included:\n",
    "1. removing punctuation\n",
    "2. lowercasing\n",
    "3. lemmatizing\n",
    "4. removing stop words\n",
    "5. keyword extraction using YAKE\n",
    "\n",
    "\n",
    "\n",
    "#### BERTopic\n",
    "\n",
    "To cluster the items, I used the keywords found by the YAKE library, and used the library BERTopic for topic modeling. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA Topic Model\n",
    "I initially tried gensim's implementation of Latent Dirichlet Allocation (LDA), but got pretty poor results. The clusters did not accurately (as judged by my spot-checking) segment item classes.\n",
    "\n",
    "This is a known problem with LDA (and topic models in general) that small text samples like in our dataset are difficult to segment. There are possible alternatives such as adding ngrams or using hierarchical topic models.\n",
    "\n",
    "For a project I worked on doing topic modeling of scientific articles, we found that adding metadata such as author of article, name of journal published in, bibliography page, etc significantly helped model performance. I would expect similar results here. If we had other information such as merchant name, url from purchase, etc, we should look to add those to the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
