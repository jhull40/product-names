{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "\n",
    "a.) If we want to understand which catalog (such as clothing, shoes, accessories, beauty, jewelry etc.) each item is, how will you make that happen?\n",
    "\n",
    "\n",
    "b.) How can you extract the additional information from the item names, such as the color, style, size, material, gender etc. if there is any?\n",
    "\n",
    "\n",
    "c.) A plus. If you write the queries/codes, or build a machine learning model to achieve the goal of a.) or b.) above on the attached dataset. Python is preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A\n",
    "\n",
    "To understand the catalog that each item belongs to, I ran built topic models to cluster items. Then, using the output, I manually labeled the output data to map a topic to a physical catalog label.\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing included:\n",
    "1. removing punctuation\n",
    "2. lowercasing\n",
    "3. lemmatizing\n",
    "4. removing stop words\n",
    "5. keyword extraction using YAKE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERTopic\n",
    "\n",
    "To cluster the items, I used the keywords found by the YAKE library, and used the library BERTopic for topic modeling.\n",
    "\n",
    "Looking at some clusters based on common words:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![topics](output/topwords.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![topic1](output/topics1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![topic2](output/topics2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![topic3](output/topics3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these common words per topic, a human can then map them to a category name.\n",
    "\n",
    "**Topic 0:** pencil, box, canvas --> Art supplies\n",
    "\n",
    "**Topic 1:** ceramic, ceramic mug, ceramic printland --> Home goods\n",
    "\n",
    "**Topic 2:** necklace, alloy necklace, necklace indian --> Jewelry "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add new items and discover the most closely related topic(s)\n",
    "\n",
    "![newterm](output/newterm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and cons\n",
    "\n",
    "Pros - \n",
    "1. Quick, easily interpretable output\n",
    "2. Can use multi-lingual BERT models\n",
    "\n",
    "\n",
    "\n",
    "Cons - \n",
    "1. Requires human labeling - not ideal\n",
    "2. Difficult to detect small topics or overlapping topics without humans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Improvements\n",
    "1. Can add labels to incorporate semi-supervised learning using a pre-defined partial topic list\n",
    "2. Can use other methods for dimensionality reduction (currently uses UMAP with HDBScan, but perhaps autoencoder?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA Topic Model\n",
    "I initially tried gensim's implementation of Latent Dirichlet Allocation (LDA), but got pretty poor results. The clusters did not accurately (as judged by my spot-checking) segment item classes.\n",
    "\n",
    "This is a known problem with LDA (and topic models in general) that small text samples like in our dataset are difficult to segment. There are possible alternatives such as adding ngrams or using hierarchical topic models.\n",
    "\n",
    "For a project I worked on doing topic modeling of scientific articles, we found that adding metadata such as author of article, name of journal published in, bibliography page, etc significantly helped model performance. I would expect similar results here. If we had other information such as merchant name, url from purchase, etc, we should look to add those to the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
